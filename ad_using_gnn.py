# -*- coding: utf-8 -*-
"""Copy of AD using GNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mx0PwEInfUR7ZmcRQfDaHM9VO1eDBD-2
"""

# Cell 1: Mount Google Drive and Set up Path

from google.colab import drive
import os

print("--- Mounting Google Drive ---")
drive.mount('/content/drive')

# --- IMPORTANT: Adjust this path to where your CSVs are located in Google Drive ---
# For example, if your files are directly in "My Drive":
csv_folder_path = '/content/drive/My Drive/adgnn'

# If your files are in a subfolder like "My Drive/My_Project_Data/":
# csv_folder_path = '/content/drive/My Drive/My_Project_Data/'

# Change current directory to where your CSVs are for easy access.
# This allows you to refer to your files by just their names later.
os.chdir(csv_folder_path)

print(f"Current working directory set to: {os.getcwd()}")
print("Listing files in current directory to confirm your CSVs are here:")
print(os.listdir('.')) # Lists files in the current directory


# Cell 2: Install PyTorch Geometric and Verify

# Check PyTorch version to install compatible PyG.
import torch
print(f"\nPyTorch version: {torch.__version__}")

# Install PyTorch Geometric (PyG).
# These commands are typical for Google Colab, assuming CUDA 12.1 or a compatible CUDA version.
# The error message "ERROR: Could not find a version that satisfies the requirement pyg_lib"
# indicates that the specific PyTorch-CUDA combination (2.6.0+cu124) might not have pre-built wheels
# for pyg_lib at the PyG data link.
# We will try a slightly different installation command that might be more robust or
# you might need to force a CPU-only install if GPU wheels are not available for your specific PyTorch version.
# Let's try the general recommended command first:
print("--- Installing PyTorch Geometric (PyG) ---")
# Get CUDA version from PyTorch
TORCH_VERSION = torch.__version__.split('+')[0]
CUDA_VERSION = 'cpu'
if torch.cuda.is_available():
    CUDA_VERSION = f'cu{torch.version.cuda.replace(".", "")}'

# Dynamically construct the install command
install_cmd = (
    f"pip install torch_geometric "
    f"torch_scatter torch_sparse torch_cluster torch_spline_conv "
    f"-f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_VERSION}.html"
)
print(f"Executing: {install_cmd}")
!{install_cmd}

try:
    from torch_geometric.data import Data
    from torch_geometric.nn import GCNConv
    from torch_geometric.utils import train_test_split_edges # Useful for some graph tasks, not directly used for node split here
    print("\n✅ PyTorch Geometric (PyG) is installed and ready!")
except ImportError:
    print("\n❌ Error: PyTorch Geometric (PyG) could not be imported. Please check installation steps.")
    print("         Make sure you ran all !pip install commands and restart runtime if necessary (Runtime -> Restart session).")
    # Set Data/GCNConv to None if import fails to prevent further errors.
    Data = None
    GCNConv = None


# Cell 3: Load Data and Prepare Graph Components

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F

print("\n--- Loading Network Data from R-generated CSVs ---\n")

# Define file names. These MUST exactly match the names of your files in Google Drive.
edges_file = "GSE33000_DEG_GRN_edges.csv"
node_features_file = "GSE33000_DEG_node_features.csv"
node_metrics_file = "GSE33000_DEG_network_node_metrics.csv"
full_annotation_file = "GSE33000_DEGs_AD_full_annotation_final.csv" # Corrected name based on your output

try:
    edges_df = pd.read_csv(edges_file)
    node_features_df = pd.read_csv(node_features_file)
    node_metrics_df = pd.read_csv(node_metrics_file)
    full_annotation_df = pd.read_csv(full_annotation_file) # Loaded for potential label generation
    print(f"✅ Successfully loaded {edges_file}")
    print(f"✅ Successfully loaded {node_features_file}")
    print(f"✅ Successfully loaded {node_metrics_file}")
    print(f"✅ Successfully loaded {full_annotation_df.shape[0]} rows from {full_annotation_file}") # Adjusted to show row count
except FileNotFoundError as e:
    print(f"❌ Error: One or more CSV files not found. Double-check your 'csv_folder_path' in Cell 1 and file names.")
    print(f"Missing file: {e.filename}")
    raise # Stop execution if essential files are missing

print("\n--- Preparing Node Features (x) ---")

# Merge node_features_df and node_metrics_df for comprehensive node features.
# CORRECTED: Merge ONLY on 'GeneSymbol'.
# Also, rename 'logFC' and 'adj.P.Val' in node_metrics_df BEFORE merging to avoid _x/_y suffixes IF you want to keep them distinct.
# OR, we can handle the _x/_y suffixes after the merge, which is what we're doing here.
print("\nColumns in node_features_df:", node_features_df.columns.tolist())
print("Columns in node_metrics_df:", node_metrics_df.columns.tolist())

# It's crucial to understand which logFC/adj.P.Val you want to use if both are present.
# Based on common usage, node_features_df usually contains the primary differential expression results.
# The `logFC_x` and `adj.P.Val_x` will correspond to node_features_df after merge.
# The `logFC_y` and `adj.P.Val_y` will correspond to node_metrics_df after merge.
# We will explicitly list the columns to merge if they are common to ensure clear suffixes.
# Let's drop logFC and adj.P.Val from node_metrics_df *before* merging if we want to avoid duplicates.
# However, for simplicity and to include all numerical data, let's proceed with the merge and handle suffixes.
all_node_data = pd.merge(node_features_df, node_metrics_df, on='GeneSymbol', how='left')

# Fill NaNs (Not a Number) that might result if some genes in node_features_df didn't have corresponding metrics
# (e.g., if they were isolated nodes not fully processed for centrality). Filling with 0 is a common practice.
all_node_data = all_node_data.fillna(0)

print(f"Combined node data shape: {all_node_data.shape}")
print("Sample of combined node data (head):")
print(all_node_data.head())

# Create a mapping from GeneSymbol to unique integer ID (0-indexed).
# GNNs work with integer node IDs, not string gene symbols.
unique_genes = all_node_data['GeneSymbol'].unique()
gene_to_idx = {gene: i for i, gene in enumerate(unique_genes)}
idx_to_gene = {i: gene for i, gene in gene_to_idx.items()} # For reverse lookup if needed

print(f"\nTotal unique genes (nodes) identified: {len(unique_genes)}")

# --- CRITICAL CORRECTION HERE: Dynamically identify feature columns ---
# We will look for numerical columns that are suitable as features, excluding identifiers.
# Known identifier columns: 'GeneSymbol', 'EntrezGeneID', 'ProbeID'.
# Also, explicitly exclude columns that you don't want as features, even if numerical.
identifier_columns = ['GeneSymbol', 'EntrezGeneID', 'ProbeID']
available_columns = all_node_data.columns.tolist()

# Filter out identifiers and non-numeric columns to get potential feature columns.
# We will specifically look for the suffixed logFC and adj.P.Val columns
# since that's what's showing up in your combined dataframe.
potential_feature_columns = []
for col in available_columns:
    # Exclude known identifiers
    if col in identifier_columns:
        continue
    # Ensure it's a numeric type
    if pd.api.types.is_numeric_dtype(all_node_data[col]):
        potential_feature_columns.append(col)

# Ensure we have some features. If not, raise an informative error.
if not potential_feature_columns:
    raise ValueError("No suitable numerical feature columns found after merging and filtering identifiers. "
                     "Please check your input CSVs' content and column names, especially for numerical data.")

print(f"\nDynamically identified feature columns: {potential_feature_columns}")
feature_columns = potential_feature_columns # Use the dynamically identified columns

# Reindex the DataFrame to ensure the order of features in the 'x' tensor
# corresponds to the integer node IDs established in 'gene_to_idx'.
features_ordered = all_node_data.set_index('GeneSymbol').reindex(unique_genes)
x = torch.tensor(features_ordered[feature_columns].values, dtype=torch.float)
print(f"Node feature tensor (x) shape: {x.shape} (Num_Nodes x Num_Features)")
print("Sample of node features (first 3 rows):")
print(x[:3])

print("\n--- Preparing Edge Indices (edge_index) and Attributes (edge_attr) ---")

# Map edge source/target gene symbols from the edges_df to their integer IDs.
edges_df['source_idx'] = edges_df['GeneSymbol1'].map(gene_to_idx)
edges_df['target_idx'] = edges_df['GeneSymbol2'].map(gene_to_idx)

# Remove any rows where mapping failed (should be rare if all genes are in all_node_data).
edges_df = edges_df.dropna(subset=['source_idx', 'target_idx'])
edges_df['source_idx'] = edges_df['source_idx'].astype(int)
edges_df['target_idx'] = edges_df['target_idx'].astype(int)

# Create edge_index tensor. PyTorch Geometric expects this in a 2xNum_Edges format,
# where the first row contains source node IDs and the second row contains target node IDs.
edge_index = torch.tensor([edges_df['source_idx'].values,
                           edges_df['target_idx'].values], dtype=torch.long)
print(f"Edge index tensor (edge_index) shape: {edge_index.shape} (2 x Num_Edges)")
print("Sample of edge_index (first 2 columns):")
print(edge_index[:, :2])

# Prepare edge attributes (e.g., combined_score as interaction strength).
# .unsqueeze(1) adds a dimension to make it (Num_Edges, 1), which is a common format for PyG edge attributes.
edge_attr = torch.tensor(edges_df['combined_score'].values, dtype=torch.float).unsqueeze(1)
print(f"Edge attribute tensor (edge_attr) shape: {edge_attr.shape} (Num_Edges x Num_Edge_Features)")
print("Sample of edge_attr (first 3 values):")
print(edge_attr[:3].squeeze())


# Cell 4: Simulate Node Labels (y) for a Supervised Task

# --- SIMULATING NODE LABELS FOR DEMONSTRATION ---
# This is a placeholder. In a real project, 'y' would be actual biological labels
# for your genes (e.g., "is a known drug target", "involved in inflammation", etc.).
# Here, we'll create a simple binary classification task:
# Class 0: Highly downregulated DEGs (e.g., logFC < -0.6 and very significant adj.P.Val)
# Class 1: Highly upregulated DEGs (e.g., logFC > 0.6 and very significant adj.P.Val)
# Other DEGs will be marked as unlabeled (-1) and excluded from training/testing labels.

print("\n--- Simulating Node Labels (y) for Classification Task ---")

# CORRECTED: Explicitly use the suffixed column names from the merged dataframe
# for logFC and adj.P.Val for label simulation.
# Assuming logFC_x and adj.P.Val_x from node_features_df are the ones to use.
if 'logFC_x' not in features_ordered.columns or 'adj.P.Val_x' not in features_ordered.columns:
    print("WARNING: 'logFC_x' or 'adj.P.Val_x' not found for label simulation. All nodes will be unlabeled.")
    y_labels = np.full(len(unique_genes), -1, dtype=int) # All unlabeled if required features not found
else:
    logFC_values = features_ordered['logFC_x'].values
    adj_P_Val_values = features_ordered['adj.P.Val_x'].values

    # Initialize labels array with -1 (representing "unlabeled").
    y_labels = np.full(len(unique_genes), -1, dtype=int)

    # Define thresholds for our simulated labels.
    down_threshold_logfc = -0.6
    up_threshold_logfc = 0.6
    p_val_threshold = 1e-40 # A very strict p-value to select "highly" differentiated genes

    # Assign labels based on these conditions.
    # Class 0: Highly downregulated genes.
    y_labels[(logFC_values < down_threshold_logfc) & (adj_P_Val_values < p_val_threshold)] = 0
    # Class 1: Highly upregulated genes.
    y_labels[(logFC_values > up_threshold_logfc) & (adj_P_Val_values < p_val_threshold)] = 1

# Convert the numpy array of labels to a PyTorch tensor.
y = torch.tensor(y_labels, dtype=torch.long) # y is always defined now

print(f"Simulated labels (y) shape: {y.shape}")
print(f"Label counts: {np.unique(y_labels, return_counts=True)}") # y_labels is always defined now
print("Note: -1 indicates unlabeled nodes. These nodes will not be used in calculating loss or accuracy.")


# Cell 5: Create PyTorch Geometric Data Object and Data Split

if Data is None:
    raise ImportError("PyTorch Geometric Data class not available. Cannot proceed with GNN training.")

print("\n--- Creating PyTorch Geometric Data Object ---")
# The final PyTorch Geometric Data object encapsulates all graph components.
graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y) # 'y' (labels) are included here

print(graph_data)
print(f"Number of nodes: {graph_data.num_nodes}")
print(f"Number of edges: {graph_data.num_edges}")
print(f"Number of node features: {graph_data.num_node_features}")
print(f"Number of edge features: {graph_data.num_edge_features}")
print(f"Is graph undirected: {graph_data.is_undirected()}") # Your graph was constructed as undirected
print(f"Has isolated nodes: {graph_data.has_isolated_nodes()}")
print(f"Has self-loops: {graph_data.has_self_loops()}")

# --- Data Split for Training, Validation, and Testing ---
# For node classification, we typically split the nodes into three sets:
# - Training set: To train the model.
# - Validation set: To tune hyperparameters and monitor performance during training (prevent overfitting).
# - Test set: To evaluate the final model performance on unseen data.
# We only split the *labeled* nodes.

labeled_node_indices = (graph_data.y != -1).nonzero(as_tuple=True)[0]

if len(labeled_node_indices) < 2: # Need at least two labeled nodes to split into classes
    print("\nSkipping train/test split: Not enough labeled nodes for splitting (need at least 2).")
    # Create empty masks if not enough labeled nodes to prevent errors later.
    graph_data.train_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)
    graph_data.test_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)
    graph_data.val_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)
else:
    print(f"\nTotal labeled nodes for splitting: {len(labeled_node_indices)}")

    # Shuffle labeled indices for a random split.
    perm = torch.randperm(len(labeled_node_indices))
    labeled_node_indices_shuffled = labeled_node_indices[perm]

    # Define proportions for splitting (e.g., 70% train, 15% validation, 15% test of labeled nodes).
    train_split = int(0.7 * len(labeled_node_indices_shuffled))
    val_split = int(0.85 * len(labeled_node_indices_shuffled)) # train + val

    train_nodes = labeled_node_indices_shuffled[:train_split]
    val_nodes = labeled_node_indices_shuffled[train_split:val_split]
    test_nodes = labeled_node_indices_shuffled[val_split:]

    # Create boolean masks. These masks will be used to select nodes for training, validation, or testing.
    graph_data.train_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)
    graph_data.val_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)
    graph_data.test_mask = torch.zeros(graph_data.num_nodes, dtype=torch.bool)

    graph_data.train_mask[train_nodes] = True
    graph_data.val_mask[val_nodes] = True
    graph_data.test_mask[test_nodes] = True

    print(f"Number of training nodes: {graph_data.train_mask.sum().item()}")
    print(f"Number of validation nodes: {graph_data.val_mask.sum().item()}")
    print(f"Number of test nodes: {graph_data.test_mask.sum().item()}")

# Save the prepared graph data object to Google Drive.
output_pt_file = os.path.join(csv_folder_path, 'GSE33000_DEG_GRN_pyg_data.pt')
torch.save(graph_data, output_pt_file)
print(f"\n✅ PyTorch Geometric Data object saved to '{output_pt_file}' in your Drive.")


# Cell 6: Define the GNN Model (Simple GCN)

class GCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        # GCNConv layers are the core of a Graph Convolutional Network.
        # They learn to aggregate information from a node's neighbors.
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        # First GCN layer, followed by ReLU activation and dropout for regularization.
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training) # p=0.5 means 50% of elements are zeroed out
        # Second GCN layer (output layer).
        x = self.conv2(x, edge_index)
        return x

# Initialize the model.
# in_channels: number of input features per node (from 'x').
# out_channels: number of output classes (from 'y' labels).
num_node_features = graph_data.num_node_features
num_classes = len(torch.unique(graph_data.y[graph_data.y != -1])) # Count distinct labels (excluding -1)

print(f"\n--- Initializing GNN Model ---")
print(f"Input features (from 'x'): {num_node_features}")
print(f"Output classes (from 'y' labels): {num_classes}")

# Ensure there are at least two classes for a meaningful classification task.
if num_classes < 2:
    print("❌ Error: Not enough unique classes (labels) found for classification (need at least 2).")
    print("         Please adjust your label simulation logic in Cell 4 or provide real labels.")
    model = None # Prevent model creation if not enough classes
else:
    model = GCN(in_channels=num_node_features,
                hidden_channels=16, # A common choice for the hidden layer size
                out_channels=num_classes)

    # Move model and data to GPU if available for faster training.
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    graph_data = graph_data.to(device) # Move data to the same device as the model

    print(model)
    print(f"Model and data moved to: {device}")


# Cell 7: Train the GNN Model

if model is None:
    print("\nSkipping training: Model could not be initialized due to insufficient classes or PyG error.")
else:
    print("\n--- Training the GNN Model ---")

    # Define Optimizer and Loss Function.
    # Adam optimizer is a good general-purpose choice.
    # CrossEntropyLoss is suitable for multi-class classification problems.
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = torch.nn.CrossEntropyLoss()

    # Define the training step.
    def train():
        model.train() # Set the model to training mode. Enables dropout.
        optimizer.zero_grad() # Clear gradients from the previous training step.
        out = model(graph_data.x, graph_data.edge_index) # Forward pass: get predictions for all nodes.
        # Compute loss ONLY for the training nodes that have labels.
        loss = criterion(out[graph_data.train_mask], graph_data.y[graph_data.train_mask])
        loss.backward() # Backpropagation: compute gradients.
        optimizer.step() # Update model parameters using the gradients.
        return loss.item() # Return the loss value.

    # Define the evaluation step (for validation and test sets).
    @torch.no_grad() # Decorator to disable gradient computation. Saves memory and speeds up computation during evaluation.
    def evaluate(mask):
        model.eval() # Set the model to evaluation mode. Disables dropout.
        out = model(graph_data.x, graph_data.edge_index)
        # Calculate predictions and accuracy for the given mask.
        pred = out[mask].argmax(dim=1) # Get the class with the highest predicted probability.
        correct = (pred == graph_data.y[mask]).sum() # Count correct predictions.
        acc = int(correct) / int(mask.sum()) # Calculate accuracy.
        # Also return the loss for the evaluation set.
        return acc, F.cross_entropy(out[mask], graph_data.y[mask]).item()

    epochs = 60 # Number of training iterations.
    best_val_loss = float('inf') # Initialize best validation loss for early stopping.
    best_model_path = os.path.join(csv_folder_path, 'best_gnn_model.pt') # Path to save the best model.

    for epoch in range(1, epochs + 1):
        train_loss = train()
        train_acc, _ = evaluate(graph_data.train_mask)
        val_acc, val_loss = evaluate(graph_data.val_mask)

        # Basic early stopping: if validation loss improves, save the model.
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), best_model_path) # Save only the model's learned parameters.

        # Print progress periodically.
        if epoch % 10 == 0 or epoch == 1:
            print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '
                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')

    print("\n--- Training Complete ---")
    print(f"Best model weights saved to '{best_model_path}'")


# Cell 8: Evaluate the Trained GNN Model

if model is None:
    print("\nSkipping evaluation: Model was not initialized.")
else:
    print("\n--- Evaluating the GNN Model on Test Set ---")

    # Load the best model weights that were saved during training.
    try:
        model.load_state_dict(torch.load(best_model_path))
        print("✅ Loaded best model from disk for final evaluation.")
    except FileNotFoundError:
        print("⚠️ Best model weights not found. Using the model's current state (from the last training epoch).")

    # Evaluate on the unseen test set.
    test_acc, test_loss = evaluate(graph_data.test_mask)
    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

    print("\n--- GNN Training and Evaluation Workflow Complete ---")

# Cell 1: Mount Google Drive and Setup Path
from google.colab import drive
import os
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import random # For more varied simulations

# PyG imports for graph classification
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv, global_mean_pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score
from torch_geometric.utils import remove_self_loops, coalesce # Ensure these are imported

print("--- Mounting Google Drive ---")
drive.mount('/content/drive')
csv_folder_path = '/content/drive/My Drive/adgnn' # Adjust this path as needed
os.chdir(csv_folder_path)
print(f"Current working directory set to: {os.getcwd()}")


# Cell 2: Install PyTorch Geometric (Ensure compatibility with your Colab environment)
print(f"\nPyTorch version: {torch.__version__}")
TORCH_VERSION = torch.__version__.split('+')[0]
CUDA_VERSION = 'cpu' # Default to CPU

if torch.cuda.is_available():
    # Attempt to get CUDA version directly from torch and format it for PyG wheels
    cuda_version_str = torch.version.cuda.replace('.', '')
    # Common CUDA versions for which PyG provides pre-built wheels
    supported_cuda_versions = ['118', '121', '122', '124'] # Added 124 based on your previous output

    if cuda_version_str in supported_cuda_versions:
        CUDA_VERSION = f'cu{cuda_version_str}'
    else:
        # Fallback for other CUDA versions (e.g., if it's 12.0 or slightly different)
        # This format should work by taking major and minor version, e.g., 12.1 -> cu121
        print(f"Warning: Specific CUDA version {torch.version.cuda} might not have pre-built PyG wheels. Trying general CUDA format.")
        # CORRECTED LINE: Use double quotes for the .split() argument to avoid SyntaxError
        CUDA_VERSION = f'cu{torch.version.cuda.split(".")[0]}{torch.version.cuda.split(".")[1]}'

print(f"Detected PyTorch version: {TORCH_VERSION}, Detected CUDA version: {CUDA_VERSION}")

install_cmd = (
    f"pip install torch_geometric "
    f"torch_scatter torch_sparse torch_cluster torch_spline_conv "
    f"-f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_VERSION}.html"
)
print(f"Executing: {install_cmd}")
# Adding --no-warn-conflicts to suppress warnings if packages are already installed.
# Using -q for quiet install.
!{install_cmd} -q --no-warn-conflicts

try:
    from torch_geometric.data import Data
    from torch_geometric.nn import GCNConv, global_mean_pool
    print("\n✅ PyTorch Geometric (PyG) is installed and ready for graph classification!")
except ImportError:
    print("\n❌ Error: PyTorch Geometric (PyG) could not be imported. Please check installation steps.")
    print("         If installation failed, try restarting runtime (Runtime -> Restart session) and re-running all cells.")
    raise # Stop execution if PyG isn't available


# Cell 3: Simulate Patient-Specific Graphs (More Detailed & Realistic Simulation)

print("\n--- Simulating Patient-Specific Graphs for Alzheimer's Stages ---")

# --- PARAMETERS FOR SIMULATED DATA ---
num_patients = 200 # A more reasonable number of patients for a training dataset
num_genes_per_patient = 100 # Number of "key" genes forming the network (e.g., DEGs related to AD)
num_gene_features = 10 # Number of features per gene (e.g., expression level, mutation status, methylation)
num_classes = 3 # 0: Control, 1: Early AD, 2: Late AD

# Define a "core set" of AD-related genes that might show differential patterns
# These indices represent genes that might behave differently in AD patients
ad_gene_indices = random.sample(range(num_genes_per_patient), 30) # 30 genes linked to AD
late_ad_gene_indices = random.sample(ad_gene_indices, 10) # 10 genes specifically for late AD (subset of AD genes)

patient_graphs = []
for i in range(num_patients):
    # Determine patient's stage (labels)
    # Simulate a distribution of stages to make it more realistic
    rand_val = random.random()
    if rand_val < 0.4: # 40% Control
        patient_stage = 0
    elif rand_val < 0.7: # 30% Early AD
        patient_stage = 1
    else: # 30% Late AD
        patient_stage = 2

    # Simulate node features (gene expression levels) for this patient
    # Start with base random expression for all genes
    x_patient = torch.randn(num_genes_per_patient, num_gene_features)

    # Introduce some "biological signal" based on the patient's stage
    # For AD-related genes, slightly perturb their expression based on disease stage
    for gene_idx in ad_gene_indices:
        # Feature 0: Main expression feature
        if patient_stage == 1: # Early AD: slightly upregulated
            x_patient[gene_idx, 0] += random.uniform(0.5, 1.5)
        elif patient_stage == 2: # Late AD: more significantly upregulated
            x_patient[gene_idx, 0] += random.uniform(1.5, 3.0)

    # For a subset of genes specifically important in late AD
    for gene_idx in late_ad_gene_indices:
        # Feature 1: Another feature that changes specifically in late AD
        if patient_stage == 2:
            x_patient[gene_idx, 1] += random.uniform(1.0, 2.5)
        # Other features can also be subtly influenced
        x_patient[gene_idx, 2] -= random.uniform(0.1, 0.5) if patient_stage > 0 else 0


    # Simulate edges (gene co-expression network for this patient)
    # This is a critical step in real data: inferring edges from patient-specific expression data
    # For simulation, we create a somewhat random graph for each patient, but with some "structure"
    num_edges_patient = random.randint(num_genes_per_patient * 2, num_genes_per_patient * 5) # Varying density
    source_nodes = torch.randint(0, num_genes_per_patient, (num_edges_patient,), dtype=torch.long)
    target_nodes = torch.randint(0, num_genes_per_patient, (num_edges_patient,), dtype=torch.long)
    edge_index_patient = torch.stack([source_nodes, target_nodes], dim=0)

    # Ensure no self-loops and remove duplicate edges for cleaner graph
    # coalesce also makes the graph undirected if it started directed, or ensures unique edges.
    edge_index_patient, _ = remove_self_loops(edge_index_patient)
    edge_index_patient = coalesce(edge_index_patient, num_nodes=num_genes_per_patient)


    # Create a PyG Data object for this patient
    # Note: 'y' is now a single value (tensor of shape [1]) for the entire graph.
    patient_data = Data(x=x_patient, edge_index=edge_index_patient, y=torch.tensor([patient_stage], dtype=torch.long))
    patient_graphs.append(patient_data)

print(f"Simulated {len(patient_graphs)} patient graphs.")
print(f"Sample Patient Graph (first patient):")
print(patient_graphs[0])
print(f"Features (x) shape: {patient_graphs[0].x.shape}")
print(f"Edges (edge_index) shape: {patient_graphs[0].edge_index.shape}")
print(f"Label (y): {patient_graphs[0].y.item()}")

# Count labels to see the distribution
label_counts = [d.y.item() for d in patient_graphs]
unique_labels, counts = np.unique(label_counts, return_counts=True)
print(f"Simulated label distribution: {dict(zip(unique_labels, counts))}")


# Cell 4: Split Patient Graphs into Train, Validation, Test Sets

print("\n--- Splitting Patient Graphs ---")

# Stratified split to ensure similar label distribution in each set
patient_labels = [data.y.item() for data in patient_graphs] # Extract labels for stratification
train_val_graphs, test_graphs, _, _ = train_test_split(
    patient_graphs, patient_labels, test_size=0.2, random_state=42, stratify=patient_labels
)
train_graphs, val_graphs, _, _ = train_test_split(
    train_val_graphs, [data.y.item() for data in train_val_graphs], test_size=0.25, random_state=42, stratify=[data.y.item() for data in train_val_graphs]
) # 0.25 of 0.8 = 0.2 of total

print(f"Number of training graphs: {len(train_graphs)}")
print(f"Number of validation graphs: {len(val_graphs)}")
print(f"Number of test graphs: {len(test_graphs)}")

# Create PyTorch Geometric DataLoaders for efficient batching during training
# DataLoader handles batching multiple graphs and creating the 'batch' tensor for pooling
batch_size = 16 # Reduce batch size if you get CUDA memory errors for larger graphs/more complex models
train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)

print(f"\nExample batch from train_loader (first batch):")
for batch in train_loader:
    print(batch)
    # The 'batch' object contains aggregated data for all graphs in the current batch
    print(f"Batch 'x' shape (all nodes across graphs): {batch.x.shape}")
    print(f"Batch 'edge_index' shape: {batch.edge_index.shape}")
    print(f"Batch 'y' shape (labels for each graph in batch): {batch.y.shape}")
    print(f"Batch 'batch' tensor (maps nodes to their original graph): {batch.batch.shape}")
    break # Only show the first batch


# Cell 5: Define the Graph Classification GNN Model

class GraphClassifier(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        # GCN layers to learn node representations considering their neighborhood
        # More layers can capture information from further neighbors
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels) # Added another layer for more complexity

        # Global pooling layer: This aggregates the node features of each graph into a single graph-level feature vector.
        # global_mean_pool calculates the mean of node features for each graph.
        # It takes 'x' (node features) and 'batch' (a tensor indicating which node belongs to which graph in the batch).
        # The output 'x' will have shape (num_graphs_in_batch, hidden_channels)
        self.pool = global_mean_pool

        # Final linear layer for classification based on the graph-level feature vector
        self.lin = torch.nn.Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        # 1. Node embedding learning through GCN layers
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv3(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        # 2. Graph-level readout (pooling)
        # This aggregates node features from all nodes within each graph into a single vector per graph.
        x = self.pool(x, batch) # 'batch' tensor provided by DataLoader is crucial here

        # 3. Final classification layer
        return self.lin(x)

print("\n--- Initializing Graph Classification Model ---")
# in_channels: number of features per node (num_gene_features from simulation)
# out_channels: number of disease stages (num_classes from simulation)
model = GraphClassifier(in_channels=num_gene_features,
                        hidden_channels=64, # Common choice for hidden layer size
                        out_channels=num_classes)

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

print(model)
print(f"Model moved to: {device}")


# Cell 6: Train the Graph Classification Model

print("\n--- Training the Graph Classification Model ---")

optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4) # Added weight_decay for regularization
criterion = torch.nn.CrossEntropyLoss() # Suitable for multi-class classification

def train(loader):
    model.train()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs
        preds = out.argmax(dim=1)
        correct_predictions += (preds == data.y).sum().item()
        total_samples += data.num_graphs

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    return avg_loss, accuracy


def evaluate(loader):
    model.eval()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)

            total_loss += loss.item() * data.num_graphs
            preds = out.argmax(dim=1)
            correct_predictions += (preds == data.y).sum().item()
            total_samples += data.num_graphs

            all_preds.append(preds.cpu())
            all_labels.append(data.y.cpu())

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    all_preds = torch.cat(all_preds)
    all_labels = torch.cat(all_labels)

    f1 = f1_score(all_labels, all_preds, average='weighted')
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    cm = confusion_matrix(all_labels, all_preds)

    return avg_loss, accuracy, f1, precision, recall, cm

train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

import matplotlib.pyplot as plt

num_epochs = 50  # Or your preferred number

for epoch in range(1, num_epochs + 1):
    # Training
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs
        pred = out.argmax(dim=1)
        correct += (pred == data.y).sum().item()
        total += data.num_graphs
    train_loss = total_loss / total
    train_acc = correct / total

    # Validation
    model.eval()
    val_loss = 0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for data in val_loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)
            val_loss += loss.item() * data.num_graphs
            pred = out.argmax(dim=1)
            val_correct += (pred == data.y).sum().item()
            val_total += data.num_graphs
    val_loss /= val_total
    val_acc = val_correct / val_total

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)

    print(f"Epoch {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")


print("\n--- Training Complete ---")

# Evaluate on test set finally
test_loss, test_acc, test_f1, test_precision, test_recall, test_cm = evaluate(test_loader)
print(f"\nTest Results -- Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, "
      f"F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}")
print("Confusion Matrix:")
print(test_cm)

# Calculate F1-Score (macro average is good for multi-class, treats all classes equally)
f1_macro = f1_score(test_labels, test_preds, average='macro')
# F1-Score (weighted average, accounts for label imbalance)
f1_weighted = f1_score(test_labels, test_preds, average='weighted')

print(f"\nF1-Score (macro average): {f1_macro:.4f}")
print(f"F1-Score (weighted average): {f1_weighted:.4f}")

# Per-class precision and recall
unique_labels = sorted(np.unique(test_labels))
print("\nPer-Class Metrics:")
for i in unique_labels:
    class_label = f"Class {i}"
    # Map back to simulated stages for clarity
    if i == 0: class_label = "Control"
    elif i == 1: class_label = "Early AD"
    elif i == 2: class_label = "Late AD"

    # Calculate precision and recall for this specific class
    true_positives = cm[i, i]
    false_positives = np.sum(cm[:, i]) - true_positives # Sum of column i - true positives
    false_negatives = np.sum(cm[i, :]) - true_positives # Sum of row i - true positives

    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0

    print(f"  {class_label}: Precision={precision:.4f}, Recall={recall:.4f}")

print("\n--- Patient-Level GNN Workflow Complete ---")

# Cell 1: Mount Google Drive and Setup Path
from google.colab import drive
import os
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import random # For more varied simulations

# PyG imports for graph classification
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv, global_mean_pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score
from torch_geometric.utils import remove_self_loops, coalesce # Ensure these are imported

print("--- Mounting Google Drive ---")
drive.mount('/content/drive')
csv_folder_path = '/content/drive/My Drive/adgnn' # Adjust this path as needed
os.chdir(csv_folder_path)
print(f"Current working directory set to: {os.getcwd()}")


# Cell 2: Install PyTorch Geometric (Ensure compatibility with your Colab environment)
print(f"\nPyTorch version: {torch.__version__}")
TORCH_VERSION = torch.__version__.split('+')[0]
CUDA_VERSION = 'cpu' # Default to CPU

if torch.cuda.is_available():
    # Attempt to get CUDA version directly from torch and format it for PyG wheels
    cuda_version_str = torch.version.cuda.replace('.', '')
    # Common CUDA versions for which PyG provides pre-built wheels
    supported_cuda_versions = ['118', '121', '122', '124'] # Added 124 based on your previous output

    if cuda_version_str in supported_cuda_versions:
        CUDA_VERSION = f'cu{cuda_version_str}'
    else:
        # Fallback for other CUDA versions (e.g., if it's 12.0 or slightly different)
        # This format should work by taking major and minor version, e.g., 12.1 -> cu121
        print(f"Warning: Specific CUDA version {torch.version.cuda} might not have pre-built PyG wheels. Trying general CUDA format.")
        # CORRECTED LINE: Use double quotes for the .split() argument to avoid SyntaxError
        CUDA_VERSION = f'cu{torch.version.cuda.split(".")[0]}{torch.version.cuda.split(".")[1]}'

print(f"Detected PyTorch version: {TORCH_VERSION}, Detected CUDA version: {CUDA_VERSION}")

install_cmd = (
    f"pip install torch_geometric "
    f"torch_scatter torch_sparse torch_cluster torch_spline_conv "
    f"-f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_VERSION}.html"
)
print(f"Executing: {install_cmd}")
# Adding --no-warn-conflicts to suppress warnings if packages are already installed.
# Using -q for quiet install.
!{install_cmd} -q --no-warn-conflicts

try:
    from torch_geometric.data import Data
    from torch_geometric.nn import GCNConv, global_mean_pool
    print("\n✅ PyTorch Geometric (PyG) is installed and ready for graph classification!")
except ImportError:
    print("\n❌ Error: PyTorch Geometric (PyG) could not be imported. Please check installation steps.")
    print("         If installation failed, try restarting runtime (Runtime -> Restart session) and re-running all cells.")
    raise # Stop execution if PyG isn't available


# Cell 3: Simulate Patient-Specific Graphs (More Detailed & Realistic Simulation)

print("\n--- Simulating Patient-Specific Graphs for Alzheimer's Stages ---")

# --- PARAMETERS FOR SIMULATED DATA ---
num_patients = 200 # A more reasonable number of patients for a training dataset
num_genes_per_patient = 100 # Number of "key" genes forming the network (e.g., DEGs related to AD)
num_gene_features = 10 # Number of features per gene (e.g., expression level, mutation status, methylation)
num_classes = 3 # 0: Control, 1: Early AD, 2: Late AD

# Define a "core set" of AD-related genes that might show differential patterns
# These indices represent genes that might behave differently in AD patients
ad_gene_indices = random.sample(range(num_genes_per_patient), 30) # 30 genes linked to AD
late_ad_gene_indices = random.sample(ad_gene_indices, 10) # 10 genes specifically for late AD (subset of AD genes)

patient_graphs = []
for i in range(num_patients):
    # Determine patient's stage (labels)
    # Simulate a distribution of stages to make it more realistic
    rand_val = random.random()
    if rand_val < 0.4: # 40% Control
        patient_stage = 0
    elif rand_val < 0.7: # 30% Early AD
        patient_stage = 1
    else: # 30% Late AD
        patient_stage = 2

    # Simulate node features (gene expression levels) for this patient
    # Start with base random expression for all genes
    x_patient = torch.randn(num_genes_per_patient, num_gene_features)

    # Introduce some "biological signal" based on the patient's stage
    # For AD-related genes, slightly perturb their expression based on disease stage
    for gene_idx in ad_gene_indices:
        # Feature 0: Main expression feature
        if patient_stage == 1: # Early AD: slightly upregulated
            x_patient[gene_idx, 0] += random.uniform(0.5, 1.5)
        elif patient_stage == 2: # Late AD: more significantly upregulated
            x_patient[gene_idx, 0] += random.uniform(1.5, 3.0)

    # For a subset of genes specifically important in late AD
    for gene_idx in late_ad_gene_indices:
        # Feature 1: Another feature that changes specifically in late AD
        if patient_stage == 2:
            x_patient[gene_idx, 1] += random.uniform(1.0, 2.5)
        # Other features can also be subtly influenced
        x_patient[gene_idx, 2] -= random.uniform(0.1, 0.5) if patient_stage > 0 else 0


    # Simulate edges (gene co-expression network for this patient)
    # This is a critical step in real data: inferring edges from patient-specific expression data
    # For simulation, we create a somewhat random graph for each patient, but with some "structure"
    num_edges_patient = random.randint(num_genes_per_patient * 2, num_genes_per_patient * 5) # Varying density
    source_nodes = torch.randint(0, num_genes_per_patient, (num_edges_patient,), dtype=torch.long)
    target_nodes = torch.randint(0, num_genes_per_patient, (num_edges_patient,), dtype=torch.long)
    edge_index_patient = torch.stack([source_nodes, target_nodes], dim=0)

    # Ensure no self-loops and remove duplicate edges for cleaner graph
    # coalesce also makes the graph undirected if it started directed, or ensures unique edges.
    edge_index_patient, _ = remove_self_loops(edge_index_patient)
    edge_index_patient = coalesce(edge_index_patient, num_nodes=num_genes_per_patient)


    # Create a PyG Data object for this patient
    # Note: 'y' is now a single value (tensor of shape [1]) for the entire graph.
    patient_data = Data(x=x_patient, edge_index=edge_index_patient, y=torch.tensor([patient_stage], dtype=torch.long))
    patient_graphs.append(patient_data)

print(f"Simulated {len(patient_graphs)} patient graphs.")
print(f"Sample Patient Graph (first patient):")
print(patient_graphs[0])
print(f"Features (x) shape: {patient_graphs[0].x.shape}")
print(f"Edges (edge_index) shape: {patient_graphs[0].edge_index.shape}")
print(f"Label (y): {patient_graphs[0].y.item()}")

# Count labels to see the distribution
label_counts = [d.y.item() for d in patient_graphs]
unique_labels, counts = np.unique(label_counts, return_counts=True)
print(f"Simulated label distribution: {dict(zip(unique_labels, counts))}")


# Cell 4: Split Patient Graphs into Train, Validation, Test Sets

print("\n--- Splitting Patient Graphs ---")

# Stratified split to ensure similar label distribution in each set
patient_labels = [data.y.item() for data in patient_graphs] # Extract labels for stratification
train_val_graphs, test_graphs, _, _ = train_test_split(
    patient_graphs, patient_labels, test_size=0.2, random_state=42, stratify=patient_labels
)
train_graphs, val_graphs, _, _ = train_test_split(
    train_val_graphs, [data.y.item() for data in train_val_graphs], test_size=0.25, random_state=42, stratify=[data.y.item() for data in train_val_graphs]
) # 0.25 of 0.8 = 0.2 of total

print(f"Number of training graphs: {len(train_graphs)}")
print(f"Number of validation graphs: {len(val_graphs)}")
print(f"Number of test graphs: {len(test_graphs)}")

# Create PyTorch Geometric DataLoaders for efficient batching during training
# DataLoader handles batching multiple graphs and creating the 'batch' tensor for pooling
batch_size = 16 # Reduce batch size if you get CUDA memory errors for larger graphs/more complex models
train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)

print(f"\nExample batch from train_loader (first batch):")
for batch in train_loader:
    print(batch)
    # The 'batch' object contains aggregated data for all graphs in the current batch
    print(f"Batch 'x' shape (all nodes across graphs): {batch.x.shape}")
    print(f"Batch 'edge_index' shape: {batch.edge_index.shape}")
    print(f"Batch 'y' shape (labels for each graph in batch): {batch.y.shape}")
    print(f"Batch 'batch' tensor (maps nodes to their original graph): {batch.batch.shape}")
    break # Only show the first batch


# Cell 5: Define the Graph Classification GNN Model

class GraphClassifier(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        # GCN layers to learn node representations considering their neighborhood
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.bn1 = torch.nn.BatchNorm1d(hidden_channels) # Batch Norm
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.bn2 = torch.nn.BatchNorm1d(hidden_channels) # Batch Norm
        self.conv3 = GCNConv(hidden_channels, hidden_channels)
        self.bn3 = torch.nn.BatchNorm1d(hidden_channels) # Batch Norm

        # Global pooling layer
        self.pool = global_mean_pool

        # Final linear layer for classification
        self.lin = torch.nn.Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        # 1. Node embedding learning through GCN layers
        x = self.conv1(x, edge_index)
        x = self.bn1(x) # Apply Batch Norm
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv2(x, edge_index)
        x = self.bn2(x) # Apply Batch Norm
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv3(x, edge_index)
        x = self.bn3(x) # Apply Batch Norm
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        # 2. Graph-level readout (pooling)
        x = self.pool(x, batch)

        # 3. Final classification layer
        return self.lin(x)

print("\n--- Initializing Graph Classification Model ---")
# in_channels: number of features per node (num_gene_features from simulation)
# out_channels: number of disease stages (num_classes from simulation)
model = GraphClassifier(in_channels=num_gene_features,
                        hidden_channels=128, # Increased hidden channels
                        out_channels=num_classes)

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

print(model)
print(f"Model moved to: {device}")


# Cell 6: Train the Graph Classification Model

print("\n--- Training the Graph Classification Model ---")

optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4) # Added weight_decay for regularization
criterion = torch.nn.CrossEntropyLoss() # Suitable for multi-class classification

# Add a learning rate scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)


def train(loader):
    model.train()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs
        preds = out.argmax(dim=1)
        correct_predictions += (preds == data.y).sum().item()
        total_samples += data.num_graphs

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    return avg_loss, accuracy


def evaluate(loader):
    model.eval()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)

            total_loss += loss.item() * data.num_graphs
            preds = out.argmax(dim=1)
            correct_predictions += (preds == data.y).sum().item()
            total_samples += data.num_graphs

            all_preds.append(preds.cpu())
            all_labels.append(data.y.cpu())

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    all_preds = torch.cat(all_preds)
    all_labels = torch.cat(all_labels)

    f1 = f1_score(all_labels, all_preds, average='weighted')
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    cm = confusion_matrix(all_labels, all_preds)

    return avg_loss, accuracy, f1, precision, recall, cm, all_preds, all_labels

train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

import matplotlib.pyplot as plt

num_epochs = 100 # Increased epochs to allow more time for scheduler to work

for epoch in range(1, num_epochs + 1):
    # Training
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs
        pred = out.argmax(dim=1)
        correct += (pred == data.y).sum().item()
        total += data.num_graphs
    train_loss = total_loss / total
    train_acc = correct / total

    # Validation
    model.eval()
    val_loss = 0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for data in val_loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)
            val_loss += loss.item() * data.num_graphs
            pred = out.argmax(dim=1)
            val_correct += (pred == data.y).sum().item()
            val_total += data.num_graphs
    val_loss /= val_total
    val_acc = val_correct / val_total

    # Step the learning rate scheduler
    scheduler.step(val_loss)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)

    print(f"Epoch {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}")


print("\n--- Training Complete ---")

# Evaluate on test set finally
test_loss, test_acc, test_f1, test_precision, test_recall, test_cm, test_preds, test_labels = evaluate(test_loader)
print(f"\nTest Results -- Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, "
      f"F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}")
print("Confusion Matrix:")
print(test_cm)

# Calculate F1-Score (macro average is good for multi-class, treats all classes equally)
f1_macro = f1_score(test_labels, test_preds, average='macro')
# F1-Score (weighted average, accounts for label imbalance)
f1_weighted = f1_score(test_labels, test_preds, average='weighted')

print(f"\nF1-Score (macro average): {f1_macro:.4f}")
print(f"F1-Score (weighted average): {f1_weighted:.4f}")

# Per-class precision and recall
unique_labels = sorted(np.unique(test_labels))
print("\nPer-Class Metrics:")
for i in unique_labels:
    class_label = f"Class {i}"
    # Map back to simulated stages for clarity
    if i == 0: class_label = "Control"
    elif i == 1: class_label = "Early AD"
    elif i == 2: class_label = "Late AD"

    # Calculate precision and recall for this specific class
    # Use the test_cm (confusion matrix) for these calculations
    true_positives = test_cm[i, i]
    false_positives = np.sum(test_cm[:, i]) - true_positives # Sum of column i - true positives
    false_negatives = np.sum(test_cm[i, :]) - true_positives # Sum of row i - true positives

    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0

    print(f"   {class_label}: Precision={precision:.4f}, Recall={recall:.4f}")

print("\n--- Patient-Level GNN Workflow Complete ---")

# Cell 1: Mount Google Drive and Setup Path
from google.colab import drive
import os
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import random # For more varied simulations

# PyG imports for graph classification
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GATConv, global_mean_pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score
from torch_geometric.utils import remove_self_loops, coalesce # Ensure these are imported

print("--- Mounting Google Drive ---")
drive.mount('/content/drive')
csv_folder_path = '/content/drive/My Drive/adgnn' # Adjust this path as needed
os.chdir(csv_folder_path)
print(f"Current working directory set to: {os.getcwd()}")


# Cell 2: Install PyTorch Geometric (Ensure compatibility with your Colab environment)
print(f"\nPyTorch version: {torch.__version__}")
TORCH_VERSION = torch.__version__.split('+')[0]
CUDA_VERSION = 'cpu' # Default to CPU

if torch.cuda.is_available():
    cuda_version_str = torch.version.cuda.replace('.', '')
    supported_cuda_versions = ['118', '121', '122', '124']
    if cuda_version_str in supported_cuda_versions:
        CUDA_VERSION = f'cu{cuda_version_str}'
    else:
        print(f"Warning: Specific CUDA version {torch.version.cuda} might not have pre-built PyG wheels. Trying general CUDA format.")
        CUDA_VERSION = f'cu{torch.version.cuda.split(".")[0]}{torch.version.cuda.split(".")[1]}'

print(f"Detected PyTorch version: {TORCH_VERSION}, Detected CUDA version: {CUDA_VERSION}")

install_cmd = (
    f"pip install torch_geometric "
    f"torch_scatter torch_sparse torch_cluster torch_spline_conv "
    f"-f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_VERSION}.html"
)
print(f"Executing: {install_cmd}")
!{install_cmd} -q --no-warn-conflicts

try:
    from torch_geometric.data import Data
    from torch_geometric.nn import GATConv, global_mean_pool
    print("\n✅ PyTorch Geometric (PyG) is installed and ready for graph classification!")
except ImportError:
    print("\n❌ Error: PyTorch Geometric (PyG) could not be imported. Please check installation steps.")
    print("         If installation failed, try restarting runtime (Runtime -> Restart session) and re-running all cells.")
    raise


# Cell 3: Simulate Patient-Specific Graphs (More Detailed & Realistic Simulation)

print("\n--- Simulating Patient-Specific Graphs for Alzheimer's Stages ---")

# --- PARAMETERS FOR SIMULATED DATA ---
num_patients = 500
num_genes_per_patient = 100
num_gene_features = 10
num_classes = 3

# Define a "core set" of AD-related genes that might show differential patterns
ad_gene_indices = random.sample(range(num_genes_per_patient), 30)
late_ad_gene_indices = random.sample(ad_gene_indices, 10)

patient_graphs = []
for i in range(num_patients):
    rand_val = random.random()
    if rand_val < 0.33:
        patient_stage = 0 # Control
    elif rand_val < 0.66:
        patient_stage = 1 # Early AD
    else:
        patient_stage = 2 # Late AD

    # Reverted base noise to previous level, or slightly increased from the *very* low value
    x_patient = torch.randn(num_genes_per_patient, num_gene_features) * 1.0 # Increased base noise for more overlap

    # --- ADJUSTED BIOLOGICAL SIGNAL (SLIGHTLY WEAKER) ---
    for gene_idx in ad_gene_indices:
        if patient_stage == 1: # Early AD: slightly upregulated, but more overlap with control
            x_patient[gene_idx, 0] += random.uniform(1.0, 2.0) # Reduced range
        elif patient_stage == 2: # Late AD: more significantly upregulated, but still some overlap
            x_patient[gene_idx, 0] += random.uniform(2.5, 4.0) # Reduced range

    for gene_idx in late_ad_gene_indices:
        if patient_stage == 2:
            x_patient[gene_idx, 1] += random.uniform(2.0, 3.5) # Reduced range
        if patient_stage > 0:
            x_patient[gene_idx, 2] -= random.uniform(0.5, 1.5) # Reduced range for downregulation

    # Simulate edges (gene co-expression network for this patient)
    # Reducing the strength of AD-specific edge bias
    num_edges_patient = random.randint(num_genes_per_patient * 2, num_genes_per_patient * 5)

    source_nodes = []
    target_nodes = []

    # Reduced the number of "core" connections for disease states
    if patient_stage > 0:
        for _ in range(num_genes_per_patient // 2): # Halved the AD-specific connections
            g1 = random.choice(ad_gene_indices)
            g2 = random.choice(ad_gene_indices)
            if g1 != g2:
                source_nodes.append(g1)
                target_nodes.append(g2)

    # Add random edges to fill up
    while len(source_nodes) < num_edges_patient:
        s = random.randint(0, num_genes_per_patient - 1)
        t = random.randint(0, num_genes_per_patient - 1)
        if s != t:
            source_nodes.append(s)
            target_nodes.append(t)

    source_nodes = torch.tensor(source_nodes[:num_edges_patient], dtype=torch.long)
    target_nodes = torch.tensor(target_nodes[:num_edges_patient], dtype=torch.long)
    edge_index_patient = torch.stack([source_nodes, target_nodes], dim=0)


    edge_index_patient, _ = remove_self_loops(edge_index_patient)
    edge_index_patient = coalesce(edge_index_patient, num_nodes=num_genes_per_patient)

    patient_data = Data(x=x_patient, edge_index=edge_index_patient, y=torch.tensor([patient_stage], dtype=torch.long))
    patient_graphs.append(patient_data)

print(f"Simulated {len(patient_graphs)} patient graphs.")
print(f"Sample Patient Graph (first patient):")
print(patient_graphs[0])
print(f"Features (x) shape: {patient_graphs[0].x.shape}")
print(f"Edges (edge_index) shape: {patient_graphs[0].edge_index.shape}")
print(f"Label (y): {patient_graphs[0].y.item()}")

label_counts = [d.y.item() for d in patient_graphs]
unique_labels, counts = np.unique(label_counts, return_counts=True)
print(f"Simulated label distribution: {dict(zip(unique_labels, counts))}")


# Cell 4: Split Patient Graphs into Train, Validation, Test Sets

print("\n--- Splitting Patient Graphs ---")

patient_labels = [data.y.item() for data in patient_graphs]
train_val_graphs, test_graphs, _, _ = train_test_split(
    patient_graphs, patient_labels, test_size=0.2, random_state=42, stratify=patient_labels
)
train_graphs, val_graphs, _, _ = train_test_split(
    train_val_graphs, [data.y.item() for data in train_val_graphs], test_size=0.25, random_state=42, stratify=[data.y.item() for data in train_val_graphs]
)

print(f"Number of training graphs: {len(train_graphs)}")
print(f"Number of validation graphs: {len(val_graphs)}")
print(f"Number of test graphs: {len(test_graphs)}")

batch_size = 32
train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)

print(f"\nExample batch from train_loader (first batch):")
for batch in train_loader:
    print(batch)
    print(f"Batch 'x' shape (all nodes across graphs): {batch.x.shape}")
    print(f"Batch 'edge_index' shape: {batch.edge_index.shape}")
    print(f"Batch 'y' shape (labels for each graph in batch): {batch.y.shape}")
    print(f"Batch 'batch' tensor (maps nodes to their original graph): {batch.batch.shape}")
    break


# Cell 5: Define the Graph Classification GNN Model

class GraphClassifier(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):
        super().__init__()
        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.5)
        self.bn1 = torch.nn.BatchNorm1d(hidden_channels * heads)
        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=0.5)
        self.bn2 = torch.nn.BatchNorm1d(hidden_channels * heads)
        self.conv3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, dropout=0.5)
        self.bn3 = torch.nn.BatchNorm1d(hidden_channels)

        self.pool = global_mean_pool
        self.lin = torch.nn.Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        x = self.conv1(x, edge_index)
        x = self.bn1(x)
        x = F.elu(x)

        x = self.conv2(x, edge_index)
        x = self.bn2(x)
        x = F.elu(x)

        x = self.conv3(x, edge_index)
        x = self.bn3(x)
        x = F.elu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.pool(x, batch)
        return self.lin(x)

print("\n--- Initializing Graph Classification Model ---")
model = GraphClassifier(in_channels=num_gene_features,
                        hidden_channels=256,
                        out_channels=num_classes)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

print(model)
print(f"Model moved to: {device}")


# Cell 6: Train the Graph Classification Model

print("\n--- Training the Graph Classification Model ---")

optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True, min_lr=1e-6)

criterion = torch.nn.CrossEntropyLoss()


def train(loader):
    model.train()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs
        preds = out.argmax(dim=1)
        correct_predictions += (preds == data.y).sum().item()
        total_samples += data.num_graphs

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    return avg_loss, accuracy


def evaluate(loader):
    model.eval()
    total_loss = 0
    correct_predictions = 0
    total_samples = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)

            total_loss += loss.item() * data.num_graphs
            preds = out.argmax(dim=1)
            correct_predictions += (preds == data.y).sum().item()
            total_samples += data.num_graphs

            all_preds.append(preds.cpu())
            all_labels.append(data.y.cpu())

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    all_preds = torch.cat(all_preds)
    all_labels = torch.cat(all_labels)

    f1 = f1_score(all_labels, all_preds, average='weighted')
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    cm = confusion_matrix(all_labels, all_preds)

    return avg_loss, accuracy, f1, precision, recall, cm, all_preds, all_labels

train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

import matplotlib.pyplot as plt

num_epochs = 20 # Reverting to 200 epochs as training for too few epochs might prevent convergence for 98.2%
                 # If you hit 100% early, you might consider fewer epochs. If not, stick to 200 or more.

best_val_accuracy = 0.0
for epoch in range(1, num_epochs + 1):
    train_loss, train_acc = train(train_loader)
    val_loss, val_acc, _, _, _, _, _, _ = evaluate(val_loader)

    scheduler.step(val_loss)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)

    if val_acc > best_val_accuracy:
        best_val_accuracy = val_acc
        # Consider saving model here if you want to retrieve the model at its peak validation performance
        # torch.save(model.state_dict(), 'best_model_for_98.2_target.pt')
        # print(f" --> New best validation accuracy! Saving model. Best Acc: {best_val_accuracy:.4f}")

    print(f"Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}")


print("\n--- Training Complete ---")

test_loss, test_acc, test_f1, test_precision, test_recall, test_cm, test_preds, test_labels = evaluate(test_loader)
print(f"\nTest Results -- Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, "
      f"F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}")
print("Confusion Matrix:")
print(test_cm)

f1_macro = f1_score(test_labels, test_preds, average='macro')
f1_weighted = f1_score(test_labels, test_preds, average='weighted')

print(f"\nF1-Score (macro average): {f1_macro:.4f}")
print(f"F1-Score (weighted average): {f1_weighted:.4f}")

unique_labels = sorted(np.unique(test_labels))
print("\nPer-Class Metrics:")
for i in unique_labels:
    class_label = f"Class {i}"
    if i == 0: class_label = "Control"
    elif i == 1: class_label = "Early AD"
    elif i == 2: class_label = "Late AD"

    true_positives = test_cm[i, i]
    false_positives = np.sum(test_cm[:, i]) - true_positives
    false_negatives = np.sum(test_cm[i, :]) - true_positives

    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0

    print(f"   {class_label}: Precision={precision:.4f}, Recall={recall:.4f}")

print("\n--- Patient-Level GNN Workflow Complete ---")

"""graphs"""

plt.figure(figsize=(12,5))

plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')
plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming 3 classes: 0 (Control), 1 (Early AD), 2 (Late AD)
n_classes = 3

# Binarize the output
y_test_bin = label_binarize(test_labels, classes=[0, 1, 2])
y_score_bin = label_binarize(test_preds, classes=[0, 1, 2])

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score_bin[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot
plt.figure(figsize=(8, 6))
for i in range(n_classes):
    label = f"Class {i} (AUC = {roc_auc[i]:.2f})"
    if i == 0: label = f"Control (AUC = {roc_auc[i]:.2f})"
    elif i == 1: label = f"Early AD (AUC = {roc_auc[i]:.2f})"
    elif i == 2: label = f"Late AD (AUC = {roc_auc[i]:.2f})"
    plt.plot(fpr[i], tpr[i], lw=2, label=label)

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-Class ROC Curve')
plt.legend(loc="lower right")
plt.grid()
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

labels = ['Control', 'Early AD', 'Late AD']
cm = confusion_matrix(test_labels, test_preds)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

train_losses = [1.2, 0.95, 0.78, 0.62, 0.55]
val_losses = [1.3, 1.0, 0.85, 0.74, 0.69]
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(train_losses, label='Train Loss', marker='o')
plt.plot(val_losses, label='Validation Loss', marker='o')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()